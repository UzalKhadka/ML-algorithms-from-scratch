{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n",
    "## Introduction\n",
    "The confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. The confusion matrix itself is relatively simple to understand, but the related terminology can be confusing.  \n",
    "<pre>\n",
    "                            |-----------------------------------|  \n",
    "                            |             Predicted             |  \n",
    "        Confusion Matrix    |-----------------------------------|  \n",
    "                            |    Negative     |    Positive     |  \n",
    "    |-----------------------------------------------------------|  \n",
    "    |          |  Negative  |  true negative  |  false positive |  \n",
    "    |  Actual  |------------|-----------------|-----------------|  \n",
    "    |          |  Positive  |  false negative |  true positive  |  \n",
    "    |-----------------------------------------------------------|  \n",
    "    Fig: Confusion Matrix for a Binary classifier (i.e. True/False, Positive/Negative, etc.)\n",
    "</pre>\n",
    "<pre>\n",
    "\n",
    "                           |----------------------------------------|  \n",
    "                           |             Predicted                  |  \n",
    "        Confusion Matrix   |----------------------------------------|  \n",
    "                           |    Cat     |    Dog     |    Mouse     |  \n",
    "    |---------------------------------------------------------------|  \n",
    "    |          |    Cat    |      7     |     4      |      4       |\n",
    "    |          |-----------|------------|---------------------------|  \n",
    "    |  Actual  |    Dog    |      2     |     7      |      1       |\n",
    "    |          |-----------|------------|---------------------------|  \n",
    "    |          |   Mouse   |      1     |     0      |      9       |\n",
    "    |---------------------------------------------------------------| \n",
    "    Fig: Confusion Matrix for a Multi-class classifier (i.e. Cat/Dog/Mouse)\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case\n",
    "The confusion matrix is a useful tool for comparing the performance of different models. For example, we might train a logistic regression model and a random forest model, and then compare their confusion matrices to decide which model is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Function\n",
    "def confusion_matrix(y_true, y_pred, labels=None):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    assert len(y_true) == len(y_pred), \"Length of y_true and y_pred must be equal\"\n",
    "\n",
    "    if labels is None or len(labels) == 0:\n",
    "        # get all unique labels from both y_true and y_pred\n",
    "        labels = np.unique(np.append(y_true, y_pred))\n",
    "    else:\n",
    "        labels = np.unique(labels)\n",
    "\n",
    "    len_labels = len(labels)  # number of unique labels\n",
    "    # create a confusion matrix\n",
    "    conf_matrix = np.zeros((len_labels, len_labels), dtype=int)\n",
    "\n",
    "    # fill the confusion matrix\n",
    "    # for each y_true sample\n",
    "    for i in range(len(y_true)):\n",
    "        # iterating over all labels to find the index of y_true sample in labels\n",
    "        for j in range(len_labels):\n",
    "            # check for match\n",
    "            if y_true[i] == labels[j]:\n",
    "                # iterating over all labels to find the index of y_pred sample in labels\n",
    "                for k in range(len_labels):\n",
    "                    # check for match and now for y_pred sample\n",
    "                    if y_pred[i] == labels[k]:\n",
    "                        # increment the value of confusion matrix at the index of y_true and y_pred sample\n",
    "                        conf_matrix[j][k] += 1\n",
    "                        break  # for optimization\n",
    "                break  # for optimization\n",
    "\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "The below tests are taken from the Scikit Learn documentation. Source: <https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [2, 0, 2, 2, 0, 1]\n",
    "y_pred = [0, 0, 2, 2, 0, 2]\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
    "y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
    "confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get 4X4 confusion matrix if we provide 4 classes to the confusion matrix function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 2, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\", \"dog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
